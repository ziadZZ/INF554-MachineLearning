{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from res.plot_lib import plot_data, plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF554: Lab 7\n",
    "\n",
    "# Introduction to PyTorch and Convolutional Neural Networks\n",
    "\n",
    "In this lab we will learn to use <a href=\"https://pytorch.org/\">PyTorch</a> to build more complex neural networks, such as Convolutional Neural Networks.\n",
    "\n",
    "The fondamental data structure in PyTorch are <a href=\"https://pytorch.org/docs/stable/tensors.html#torch.Tensor\">Tensors</a>. If you are familiar with Numpy arrays, you will find it easy to adapt to work with tensors. You may also take a look at the [tensor_tutorial](extras/tensor_tutorial.ipynb) for some examples.\n",
    "\n",
    "Let's generate some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #if you have a GPU with CUDA installed, this may speed up computation\n",
    "\n",
    "#let's generate some data\n",
    "X, Y = make_moons(n_samples=500, noise=.2)\n",
    "\n",
    "plot_data(torch.from_numpy(X).float(), torch.from_numpy(Y).long(), zoom=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.3)\n",
    "\n",
    "#we need to convert the data from Numpy arrays to Tensors\n",
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device)\n",
    "Y_train = torch.from_numpy(Y_train).long().to(device)\n",
    "Y_test = torch.from_numpy(Y_test).long().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first model\n",
    "\n",
    "As a first exercise, we will re-implement the NN that we created for Lab6 using PyTorch. We have seen that the fundamental blocks of NNs are *layers*. PyTorch provides various implementations for a great number of widely used layers. For instance, to apply a linear transformation:\n",
    "\n",
    "`nn.Linear(input_size, output_size, bias=True)`\n",
    "\n",
    "The layers are organized into <a href=\"https://pytorch.org/docs/stable/nn.html#containers\">Containers</a>. A standard and flexible container is the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\">Module</a> container. However, if we need a simple sequential network and don't need to reference the different layers, we can use the simplified <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential\">Sequential</a> container.\n",
    "\n",
    "> **Task 1.** Implement a sequential model (named `model`) with an input size of 2, a hidden layer of 16 units with ReLU activation. Note that the softmax output layer is not necessary as it is already calculated by the crossentropy loss we use : `nn.CrossEntropyLoss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hunits=16\n",
    "#INSERT YOUR CODE HERE\n",
    "model = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose the *loss* function and the *optimizer* and we start training our model.\n",
    "Take a look at the various <a href=\"https://pytorch.org/docs/stable/optim.html\">optimizers</a> and <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">loss</a> functions available in Torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) #if you have CUDA, this will make computation faster\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1) #actually SGD is just GD in this case\n",
    "\n",
    "#init performance measures\n",
    "losses = []\n",
    "tr_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(5000):\n",
    "    output=model.forward(X_train)\n",
    "    loss = loss_function(output, Y_train)\n",
    "    optimizer.zero_grad() #required since pytorch accumulates the gradients\n",
    "    loss.backward() #backpropagation step\n",
    "    optimizer.step() #update the parameters\n",
    "    \n",
    "    #update loss and accuracy\n",
    "    losses.append(loss.data)\n",
    "    output_te=model(X_test)\n",
    "    tr_acc.append(accuracy_score(Y_train.cpu(), torch.max(output.cpu(), 1)[1]))\n",
    "    test_acc.append(accuracy_score(Y_test.cpu(), torch.max(output_te.cpu(), 1)[1]))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "ax1.plot(losses)\n",
    "ax1.set_title(\"Training Loss\")\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax2.plot(test_acc, c='r', label='test')\n",
    "ax2.plot(tr_acc, c='b', label='train')\n",
    "ax2.set_title(\"Train and test accuracy\")\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(torch.from_numpy(X).float(), torch.from_numpy(Y).long(), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task 2.** (a) Run the experiment again, modifying the number of units (try 8 and 32), and compare with the results seen in Lab 6. (b) modify the activation function as tanh. (c) Modify the learning rate to 0.01 and observe the results with different number of units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Images\n",
    "\n",
    "For the next tasks we will load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "dataset_tr = datasets.MNIST('./data', train=True, download=True, transform=transform) #Change download to False once you download the dataset the first time\n",
    "dataset_te = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_tr,batch_size=64,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_te, batch_size=1000,shuffle=True)\n",
    "\n",
    "#load training data\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Task 3**: implement a fully connected NN with 2 relu activation layers. Note that the image size is 28x28 but you will need to reshape it as a vector of 784 elements.\n",
    "For the output layer, we will use log_softmax and for the loss, we will use the negative log-likelihood loss (nll_loss), both for numerical stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        #TODO: insert your code here\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO: insert your code here\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    log_interval=100\n",
    "    model.train() #set model in train mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        #TODO: introduce the loss here\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() #set model in test mode\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the loss and accuracy of our FCNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "\n",
    "model_fnn = FCNN(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(model_fnn, device, train_loader, optimizer, epoch)\n",
    "    test(model_fnn, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see visualize how different units react to the input; in particular, the following code is useful to show the activations of each unit with respect to the input class. We are going to look in particular into the output of layer 2.\n",
    "\n",
    "A note about how LayerActivations works: it is based on pytorch *hooks*. Hooks are used for inspecting / modifying the output and the gradients of a layer. Hooks can be registered on a Module or a Tensor.The hook can be a forward hook or a backward hook. The forward hook will be executed when a forward call is executed. The backward hook will be executed in the backward phase. In our case we use a forward hook to visualize the output of a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerActivations():\n",
    "    #to look into the layers and register the activation values\n",
    "    features=None #the activation values\n",
    "    \n",
    "    def __init__ (self, model_layer):\n",
    "        #model_layer: the layer to be monitored\n",
    "        self.hook = model_layer.register_forward_hook(self.hook_fn)\n",
    "    \n",
    "    def hook_fn(self,module,input,output):\n",
    "        self.features = output.cpu()\n",
    "        \n",
    "    def remove(self): #call this once you've read the values\n",
    "        self.hook.remove()\n",
    "\n",
    "def getActivations(model, model_layer, images):\n",
    "    \"\"\"Input:\n",
    "      model: (nn.Module) the model from which we need to visualize layers\n",
    "      model_layer: (nn.Module) the layer to be visualized\n",
    "      images: tensor of size [n_images, channel, img_x, img_y]\n",
    "    Output:\n",
    "      activations\n",
    "    \"\"\"\n",
    "    conv_out = LayerActivations(model_layer)\n",
    "    o = model(images)\n",
    "    act = conv_out.features\n",
    "    conv_out.remove()\n",
    "    return act\n",
    "\n",
    "for images, targets in test_loader:\n",
    "    act=getActivations(model_fnn, model_fnn.linear2, images.to(device))\n",
    "    \n",
    "    M=torch.zeros([n_hidden, 10, 1000], dtype=torch.float32)\n",
    "    for u in range(n_hidden):\n",
    "        for i in range(1000):\n",
    "            M[u][targets[i].data][i]=act[i][u].item()\n",
    "    \n",
    "    A=torch.mean(M, dim=2)\n",
    "    \n",
    "    plt.figure(figsize=(15,13))\n",
    "    for i in range(n_hidden):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.bar(x=np.arange(10), height=A[i].numpy())\n",
    "        plt.ylim=(-1.5, 1.5)\n",
    "        plt.xticks(np.arange(10))\n",
    "        plt.xlabel(\"Input Digit\")\n",
    "        plt.title(\"Avg. activations for unit \"+str(i+1))\n",
    "    \n",
    "    plt.show()\n",
    "    break #no need to go further, we are testing so the activations won't change\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Let's see if we can do better: with images, convolutional layers are more efficient than Dense layers since they can capture local information in the images. See also <a href=\"https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\">this page</a> for a more complete overview of CNNs.\n",
    "\n",
    ">**Task 4:** implement a CNN with 2 <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\">convolutional layers</a> each followed by a <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\">max pooling</a> layer (kernel_size=2). Complete the network with 2 fully connected layers, where the final layer has 50 input units (and 10 outputs, one for each class). Kernel size for the convolutional layers will be 5.\n",
    "\n",
    "If you use the default options for stride (1) and padding (0), the image width and height after each convolution will change as follows: $W'=W-(K-1)$, where $K$ stands for the kernel size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        #insert your code here\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        #initial dimensions for x will be [64, 1, 28, 28]\n",
    "        #insert your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(model_cnn, device, train_loader, optimizer, epoch)\n",
    "    test(model_cnn, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the feature maps for the two convolution layers using the `getActivations` function that we introduced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, targets in test_loader:\n",
    "    act= getActivations(model_cnn, model_cnn.conv1, images.to(device))\n",
    "    act2= getActivations(model_cnn, model_cnn.conv2, images.to(device))\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,50))\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=0.8,hspace=0, wspace=0.2)\n",
    "    for i in range(n_features):\n",
    "        ax = fig.add_subplot(12,5,i+1,xticks=[],yticks=[])\n",
    "        ax.imshow(act[0][i].cpu().detach().numpy(), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    fig = plt.figure(figsize=(20,50))\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=0.8,hspace=0, wspace=0.2)\n",
    "    for i in range(n_features):\n",
    "        ax = fig.add_subplot(12,5,i+1,xticks=[],yticks=[])\n",
    "        ax.imshow(act2[0][i].cpu().detach().numpy(), cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more challenging dataset\n",
    "\n",
    "The MNIST dataset is relatively simple to solve as you can see from the score obtained above. Let's take a look to a more challenging task such as <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR-10</a>. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. Batch size is 100 for the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 32*32   # images are 32x32 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "transform=transforms.Compose([ #normalization on 3 channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "        ])\n",
    "\n",
    "dataset_tr = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "dataset_te = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_tr,batch_size=100,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_te, batch_size=1000,shuffle=True)\n",
    "\n",
    "#load training data\n",
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Task 5:** adapt the CNN developed for MNIST on the CIFAR-10 dataset and look at the results. Notice that the CIFAR images use 3 channels (RGB) instead of 1 channel (black and white). Run 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        #insert your code here\n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        #initial dimensions for x will be [100, 3, 32, 32]\n",
    "        #insert your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 10 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.05, momentum=0.5)\n",
    "\n",
    "for epoch in range(0, 2):\n",
    "    train(model_cnn, device, train_loader, optimizer, epoch)\n",
    "    test(model_cnn, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Task 6:** Use your intuition to improve the accuracy of the network. You may vary any parameter and the architecture of the network as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
